---
title: 'Monday Makeover: Biggest Fast Food Chains in America'
author: "Billy Caughey"
date: "`r format(Sys.time(), '%d %b %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

options(scipen = 9999)

```

## Introduction

As an R programmer, and statistician, I like to continuously be improving. This requires participating in [RPubs]("http://www.rpubs.com/"), taking online courses, participating in meet up groups, and many other avenues. One which came up recently that I did not know of before is [_Monday Makeover_]("https://www.makeovermonday.co.uk/").

_Monday Makeover_ is a weekly event in the global Tableau community I first encountered at the Tableau Conference 2019. At the very heart of _Monday Makeover_ is the prospect of teaching and learning the art of visualization using Tableau.  Each week a visualization is selected and the data used to create the data is made public. _Monday Makeover_ participants are invited to create new visualizations with the data. These visualizations are reviewed and discussed by two Tableau experts during the week. Additionally, these Tableau visuals are made public for download and review for anyone interested in how the visuals were built.

In this post, I will participate in revisualizing the post for _Monday Makeover_. Additionally, I will be making a statistical analysis as well.

## Biggest Fast Food Chains in America

This weeks data set (week of 9 Dec 2019) comes from an article titled ["Ranked: Biggest Fast Food Chains in America"]("https://www.visualcapitalist.com/biggest-fast-food-chains-in-america/"). This article has a nice infographic visualizing sales in the U.S. (2017), number of locations in the U.S., and restaurant category. To me, the story goes has a large focus on sales. There is also a comparison of franchise/license and company units. Although this comparison is nice, I wonder if there is a connection between the number of units and sales. This will be my initial visualization.

## Comparing Sales and Number of Locations 

In reviewing this week's article, I find myself asking if there is an association between sales and number of locations. As such, I am going to be building this visual to see if there is a potential to make a statistical statement.

```{r libraries}

library(tidyverse)
library(broom)
library(ggplot2)
library(Amelia)
library(readr)
library(readxl)
library(httr)
library(knitr)
library(scales)
library(tree)
library(rpart.plot)
library(rattle)

GET("https://query.data.world/s/42hqvpcooejjm6ao6uwqvvduedwrof", write_disk(tf <- tempfile(fileext = ".xlsx")))
df <- read_excel(tf)

```

Now that's the data is imported, I usually take a `glimpse` (yes, that is a pun on a function in `R`). Then I like to see if there is any missing data.

```{r structure}

# Structure of Data
glimpse(df)

# Missingness Map
missmap(df, col = c("Yellow","Black"))

```

With no missing data, I am ready to plot sales against number of locations. This will be done using the `ggplot2` library. Before this plot is built, I will classify each restaurant into a type (using the article as a reference) and color each data point according to it's type. 

```{r classify and plotting}

restaurant_category <- function(x){
    if(x %in% c("McDonald's","Wendy's","Burger King","Sonic Drive-In","Jack in the Box","Carl's Jr.",
                "Whataburger","Hardee's","Five Guys","Culver's")){
        return("hamburger")
    } else if(x %in% c("Zaxby's","KFC","Popeye's","Wingstop","Chick-fil-A","Bojangles'")){
        return("chicken")
    } else if(x %in% c("Subway","Panera Bread","Arby's","Jimmy John's")){
        return("sandwich") 
    } else if(x %in% c("Little Caesars","Domino's","Pizza Hut","Papa John's")) {
        return("pizza")
    } else if(x %in% c("Taco Bell","Chipotle","Panda Express")){
        return("tex-mex or asian")
    } else {
        return("snack")
    }
}

df <- df %>%
    mutate(restaurant_type = sapply(Chain, restaurant_category),
           `Sales (U.S., 2017)` = `Sales (U.S., 2017)` / 1000000000)

df %>%
    ggplot(aes(y = `Sales (U.S., 2017)`, 
               x = `# of Locations (U.S.)`,
               color = restaurant_type)) +
    geom_point(size = 2.5, alpha = 0.5) +
    labs(y = "Sales (U.S., 2017, in Billons)",
         color = "Restaurant Type",
         x = "Number of Locations") +
    ggtitle("Sales vs Number of Locations, 2017") +
    scale_x_continuous(label = comma) +
    scale_y_continuous(label = comma) +
    theme(axis.title.x = element_text(size = 16),
          axis.text.x = element_text(size = 12),
          axis.title.y = element_text(size = 16),
          axis.text.y = element_text(size = 12),
          plot.title = element_text(size = 20)) +
    theme_bw()

```

This plot reveals a linear association between these two fields. Interestingly enough, these types of restaurant doesn't impact the trend either. Both of these discoveries are interesting to me because they defy my own personal beliefs. With that said, this is why we do analytics. Personal beliefs are great, but once the truth is known, power is gained.

## Statistical Analysis

### Tree Regressions

On first look, this trend appears linear, which would lend nicely to linear regression. With linear regression is well documented, I wanted to do something different. Natually, a tree regression came to mind. A tree regression is more robust than a linear regression and it is easier to explain. Literature for the tree regression can found in the text ["Introduction to Statistical Learning"]("http://faculty.marshall.usc.edu/gareth-james/ISL/getbook.html").

```{r tree regression}

mod1 <- rpart(`Sales (U.S., 2017)` ~ `# of Locations (U.S.)`, 
              method = "anova", 
              data = df)

summary(mod1)

fancyRpartPlot(mod1)

```

This regression suggests two decision points. The first, is there less than 5,678 locations, suggests if this is false the restaurant has an estimated sales of 13 billion. If the organization does have less than 5.678, then it is split again. This time, the node is if there are less than 2,027 locations. If this is true, then there is an estimated 1.7 billion in sales. If the node choice is false, there is an estimated sales of 4.3 billion in sales.

Is this a perfect analysis? Without testing the estimating power with cross validation, there really is no way to know. With that said, that is for another post! 

### Linear Regression

Alright, I couldn't help myself. I want to perform a linear regression as well. The assumptions will also be checked. It should be noted the output for linear regression will be different. Tree regressions will print out what the expected outcome for the outcome variable. Linear regression will produce the beta coefficients to compute the expected outcome. For kicks and giggles, the assumptions will also be checked until an assumption fails or we can show the regression satisfies all the assumptions. Also, before we continue, the names will need to be adjusted. For some reason, the "(" and ")" characters cause some grief for the `lm` function.

```{r linear regression}

df <- df %>%
    rename(Sales = `Sales (U.S., 2017)`,
           Locations = `# of Locations (U.S.)`)

mod2 <- lm(Sales ~ Locations, data = df)
summary(mod2)

```

So, what does this regression suggest? First, the $R^2$ suggests there are probably more variables needed to predict Sales. With that said, if a restaurant chain increases their locations by 1, they can expect an increase in sales of `r round(summary(mod2)$coefficients[2]*1000000000,2)` dollars. 

Now, we need to consider the assumptions of linear regression. The first assumption is the mean of the residuals is zero. We can see the mean is essentially zero.

```{r residual}

mean(summary(mod2)$residuals)

```

The next two assumptions are regarding homoscedasticity and normality of residuals. We will make some plots to view this.

```{r Homoscedasticity}

par(mfrow=c(2,2))
plot(mod2)

```

We consider the top-right and the bottom-left plots. If there is homoscedasticity, there would be no patterns in the plots. Upon review, there is definitely a pattern. Most likely, this is due to the outliers in sales (McDonald's) and locations (Subway). Thus, there is heteroscedasticity in the model. 

Using the top right plot, we can see a Q-Q plot. This plot is used to determine normality. In this case, the normality of the error terms. If there is normality, there would be a linear line across all points. Unfortunately, this plot shows there is not normality in the residuals. This assumption fails.

The next assumption we check is autocorrelation. We do this with the `acf` function. 

```{r autocorrelation}

acf(summary(mod2)$residuals)

```

This is very comforting! The residuals converge to zero! The other comforting item is the change in sign in convergence. All these suggest there is no autocorrelation in the model.

The next assumption is checking if the residuals are correlated with the number of locations. Our goal is to show there is no correlation. We can do this with the `cor.test` function.

```{r correlation}

cor.test(df$Locations,summary(mod2)$residuals)

```

With a rather large p-value, it is safe to say there is no correlation here we should be concerned with.

Is the linear model a good model? Probably not the best. There are a few assumptions which fail and need to be addressed. There are methods to address these assumptions, but again, that is for another post.

## Conclusion

I want to thank the folks over at _Monday Makeover_ for providing a lane for me to practice statistics. It was enjoyable to use some fun methods and think of a visual that sparked ideas of methods to be used. I also want to point out this can be done with loads of data sets. I would encourage you to find a data set and practice!

Until next week, have fun computing!